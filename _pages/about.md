---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

ç« ç€šé€¸çš„ä¸»è¦ç ”ç©¶æ–¹å‘ä¸ºå¤æ‚åœºæ™¯ä¸‹çš„å£°çº¹è¯†åˆ«ã€å…ƒå­¦ä¹ ä¸æ¨¡å¼è¯†åˆ«, ä½œä¸ºä¸»è¦å‚ä¸è€…å‚åŠ äº†å›½å®¶è‡ªç„¶ç§‘å­¦åŸºé‡‘é¢ä¸Šé¡¹ç›®ã€æ–°å¤§é™†æ¨ªå‘é¡¹ç›®ç­‰ç§‘ç ”ä¸åˆä½œé¡¹ç›®, å¹¶åœ¨**ICASSP**ã€**Interspeech**ç­‰ä¿¡å·å¤„ç†çš„å›½é™…é¡¶å°–ä¼šè®®ä¸Šå‘è¡¨3ç¯‡ä¸€ä½œè®ºæ–‡ã€‚

<!-- My research interest includes neural machine translation and computer vision. I have published more than 100 papers at the top international AI conferences with total <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'>google scholar citations <strong><span id='total_cit'>260000+</span></strong></a> (You can also use google scholar badge <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'><img src="https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>). -->


# ç ”ç©¶æ–¹å‘
- **è¯­éŸ³ä¿¡æ¯å¤„ç†**: å¤æ‚åœºæ™¯ä¸‹çš„å£°çº¹è¯†åˆ«
- **æ¨¡å¼è¯†åˆ«ä¸æœºå™¨å­¦ä¹ **: å…ƒå­¦ä¹ , å¯¹æŠ—æ”»å‡»

# ğŸ“– Educations
- *2020.09 - è‡³ä»Š*, ç¡•å£«å­¦ä½, å¤©æ´¥å¤§å­¦, æ™ºèƒ½ä¸è®¡ç®—å­¦éƒ¨, è½¯ä»¶å·¥ç¨‹ä¸“ä¸š, å¯¼å¸ˆ: ç‹é¾™æ ‡ã€å…šå»ºæ­¦, å¤–å¯¼: Kong Aik Lee (Senior Scientist)
- *2016.09 - 2020.07*, å­¦å£«å­¦ä½, äº‘å—å¤§å­¦, å›½å®¶ç¤ºèŒƒæ€§è½¯ä»¶å­¦é™¢, ä¿¡æ¯å®‰å…¨ä¸“ä¸š, å¯¼å¸ˆ: è°¢è¯šå‰¯æ•™æˆ

# Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICASSP 2022</div><img src='images/icassp2022.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Learning Domain-Invariant Transformation for Speaker Verification (CCF B)](https://ieeexplore.ieee.org/abstract/document/9747514)

**Hanyi Zhang**, Longbiao Wang, Kong Aik Lee, Meng Liu, Jianwu Dang, Hui Chen

- é’ˆå¯¹å£°çº¹è¯†åˆ«ç³»ç»Ÿåœ¨å®é™…åº”ç”¨ä¸­æ‰€é¢ä¸´çš„ç”±äºé‡‡å½•æ–¹å¼å’Œè¯´è¯é£æ ¼ç­‰å†…åœ¨å’Œå¤–åœ¨å› ç´ ä¸åŒ¹é…è€Œå¯¼è‡´çš„åŸŸæ¼‚ç§»é—®é¢˜, æå‡ºäº†å…ƒæ³›åŒ–è½¬æ¢ä»¥è‡ªé€‚åº”åœ°å°†æå–çš„ç‰¹å¾æ˜ å°„åˆ°åŸŸä¸å˜çš„åµŒå…¥ç©ºé—´ä¸­, å¹¶å®ç°äº†æ”¯æŒé«˜é˜¶æ¢¯åº¦çš„é€šç”¨æ¶æ„ã€‚è¯¥æ–¹æ³•é€‚ç”¨äºä¸åŒçš„ä¸»å¹²ç½‘ç»œ, åœ¨æœªè§é¢†åŸŸä¸Šå–å¾—äº† 16% çš„ç›¸å¯¹æ€§èƒ½æå‡ã€‚[[Code]](https://github.com/MiukkaZh/MGT)

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICASSP 2021</div><img src='images/icassp2021.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Meta-Learning for Cross-Channel Speaker Verification (CCF B)](https://ieeexplore.ieee.org/abstract/document/9413978)

**Hanyi Zhang**, Longbiao Wang, Kong Aik Lee, Meng Liu, Jianwu Dang, Hui Chen

- ä¸ºé™ä½ä¿¡é“ä¸åŒ¹é…å¯¹å£°çº¹è¯†åˆ«ç³»ç»Ÿé€ æˆçš„ä¸åˆ©å½±å“, æå‡ºäº†å…ƒè¯´è¯äººåµŒå…¥ç½‘ç»œæ¥ä¼˜åŒ–è¯­éŸ³åµŒå…¥åœ¨å­ç©ºé—´ä¸­çš„å±€éƒ¨ä¸å…¨å±€åˆ†å¸ƒã€‚åœ¨ä¸å¢åŠ é¢å¤–å‚æ•°çš„å‰æä¸‹, å–å¾—äº† 10% çš„ç›¸å¯¹æ€§èƒ½æå‡ã€‚
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Interspeech 2020</div><img src='images/interspeech2020.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Adversarial Separation Network for Speaker Recognition (CCF C)](https://www.isca-speech.org/archive_v0/Interspeech_2020/pdfs/1966.pdf)

**Hanyi Zhang**, Longbiao Wang, Yunchun Zhang, Meng Liu, Kong Aik Lee, Jianguo Wei

- ä¸ºé˜²æ­¢å£°çº¹è¯†åˆ«ç³»ç»Ÿè¢«ä¸æ˜“å¯Ÿè§‰çš„å¯¹æŠ—æ”»å‡»æ‰€å¹²æ‰°, æå‡ºäº†å¯¹æŠ—åˆ†ç¦»ç½‘ç»œä»¥ä»å¯¹æŠ—æ ·æœ¬ä¸­æŠ½ç¦»å¯¹æŠ—æ‰°åŠ¨, å¹¶æ¢å¤è‡ªç„¶æ ·æœ¬ã€‚é¢å¯¹ä¸åŒå¼ºåº¦ã€ä¸åŒç±»å‹çš„å¯¹æŠ—æ”»å‡», è¯¥æ–¹æ³•å‡æ˜¾è‘—æé«˜äº†å£°çº¹è¯†åˆ«ç³»ç»ŸæŠµå¾¡å¯¹æŠ—æ”»å‡»çš„èƒ½åŠ›ã€‚
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">IEEE TASLP</div><img src='images/new.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**Meta-Generalization for Domain-Invariant Speaker Verification (IEEE TASLP; SCI Q1; Under review)**

**Hanyi Zhang**, ...

- é’ˆå¯¹éƒ¨ç½²åœ¨å®é™…åº”ç”¨ä¸­çš„å£°çº¹è¯†åˆ«ç³»ç»Ÿæ‰€é¢ä¸´çš„æœªè§åŸŸå’Œå¤šå˜é‡æŒ‘æˆ˜, é‡‡ç”¨åŸºäºåº¦é‡å’Œé«˜é˜¶æ¢¯åº¦çš„ä¼˜åŒ–ç­–ç•¥, ç»“åˆåˆ›æ–°æ€§çš„å…ƒä»»åŠ¡é‡‡æ ·æ–¹æ¡ˆ, é™ä½äº†æ³›åŒ–ç½‘ç»œè®­ç»ƒçš„éš¾åº¦, å¤§å¹…æå‡äº†å£°çº¹è¯†åˆ«ç³»ç»Ÿåœ¨å¤„ç†æœªè§åŸŸçš„è¯­éŸ³æ—¶çš„æ€§èƒ½ã€‚
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ASRU 2021</div><img src='images/ASRU.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[DeepLip: A Benchmark for Deep Learning-Based Audio-Visual Lip Biometrics](https://ieeexplore.ieee.org/abstract/document/9688240)

Meng Liu, Longbiao Wang, Kong Aik Lee, **Hanyi Zhang**, Chang Zeng, Jianwu Dang

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Electronics 2020</div><img src='images/electronics.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Generative Adversarial Network-Based Neural Audio Caption Model for Oral Evaluation (SCI)](https://www.mdpi.com/2079-9292/9/3/424)

Liu Zhang, Chao Shu, Jin Guo, **Hanyi Zhang**, Cheng Xie, Qing Liu

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICEBE 2019</div><img src='images/icebe.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Speech Evaluation Based on Deep Learning Audio Caption](https://link.springer.com/chapter/10.1007/978-3-030-34986-8_4)

Liu Zhang, **Hanyi Zhang**, Jin Guo, Detao Ji, Qing Liu, Cheng Xie

</div>
</div>

# ğŸ’¬ Invited Talks
### ä¸»è¦å‚ä¸è€…
- *2021.05 - è‡³ä»Š*, å›½å®¶è‡ªç„¶ç§‘å­¦åŸºé‡‘é¢ä¸Šé¡¹ç›®, é¢å‘å¤æ‚ç¯å¢ƒçš„å£°çº¹è¯†åˆ«ä¸å£°çº¹åæ¬ºè¯ˆç ”ç©¶, NO: 62176182
- *2021.08 - è‡³ä»Š*, æ–°å¤§é™†æ¨ªå‘é¡¹ç›®
- *2019.02 - 2020.05*, â€œåŸºäºæ·±åº¦å­¦ä¹ çš„è¯­éŸ³è¯„ä»·â€æ ¡ä¼åˆä½œé¡¹ç›®
### å‚ä¸è€…
- *2020.08 - è‡³ä»Š*, ç§‘æŠ€éƒ¨å›½å®¶é‡ç‚¹ç ”å‘è®¡åˆ’â€œæ™ºèƒ½æœºå™¨äººâ€ä¸“é¡¹è¯¾é¢˜, åŸºäºè¯­è¨€è®¤çŸ¥æœºç†çš„ç±»è„‘è‡ªç„¶è¯­è¨€è¯†åˆ«ä¸äº¤äº’
- *2020.08 - 2021.12*, å›½å®¶è‡ªç„¶ç§‘å­¦åŸºé‡‘é¢ä¸Šé¡¹ç›®, é¢å‘æ··å“ç¯å¢ƒçš„å¤šå£éŸ³è¯­éŸ³è¯†åˆ«ç ”ç©¶, No. 61771333


# ä¸“åˆ©ä¸è¯ä¹¦
- ä¸­å›½å‘æ˜ä¸“åˆ©, èåˆæ·±åº¦è¯­è¨€ç”Ÿæˆæ¨¡å‹çš„è¯­è¨€è¡¨è¾¾èƒ½åŠ›è¯„ä»·æ–¹æ³•å’Œç³»ç»Ÿ, CN111341346A
- è½¯ä»¶è‘—ä½œæƒ, åŸºäºç°åº¦å›¾çš„æ¶æ„æ–‡ä»¶åˆ†ç±»è½¯ä»¶, 2017SR601808
- ä¿¡æ¯å®‰å…¨å·¥ç¨‹å¸ˆ (è½¯è€ƒè¯ä¹¦)
- è‹±è¯­å…­çº§
- å›½å®¶ä¿¡æ¯å®‰å…¨æ°´å¹³è®¤è¯ (NISP) ä¸€çº§


# ğŸ– Honors and Awards
- *2019.10* æœ¬ç§‘ç”Ÿå›½å®¶å¥–å­¦é‡‘, ä¸­åäººæ°‘å…±å’Œå›½æ•™è‚²éƒ¨
- *2019.05* ç¬¬äº”å±Š â€œäº’è”ç½‘+â€ åˆ›æ–°åˆ›ä¸šå¤§èµ›çœèµ›é“¶å¥–
- *2019.04* ç¬¬åå±Š â€œè“æ¡¥æ¯â€ å¤§èµ›äº‘å—èµ›åŒºäºŒç­‰å¥–
- *2019.04* â€œæœªæ¥æ¯â€é«˜æ ¡ AI æŒ‘æˆ˜èµ›è¥¿å—èµ›åŒºç¬¬äºŒå
- *2021.11* ä¸‰å¥½å­¦ç”Ÿ, å¤©æ´¥å¤§å­¦
- *2021.09, 2020.09* ä¸€ç­‰å¥–å­¦é‡‘, å¤©æ´¥å¤§å­¦
- *2020.06* äº‘å—å¤§å­¦ä¼˜ç§€æœ¬ç§‘å­¦ç”Ÿæ¯•ä¸šè®ºæ–‡; äº‘å—å¤§å­¦ä¼˜ç§€æ¯•ä¸šç”Ÿ
- *2017.10, 2018.10* å­¦ä¸šå¥–å­¦é‡‘, äº‘å—å¤§å­¦


# ç§‘ç ”æœåŠ¡
- *2022.03 - 2022.05*, å¤©æ´¥å¤§å­¦ç¡•å£«ç”Ÿè¯¾ç¨‹ã€Šæ™ºèƒ½ç½‘è”æ±½è½¦æŠ€æœ¯ã€‹åŠ©æ•™
- *2021.08 - 2022.01*, å¤©æ´¥å¤§å­¦æœ¬ç§‘ç”Ÿè¯¾ç¨‹ã€Šè¯­éŸ³ä¿¡æ¯å¤„ç†ã€‹åŠ©æ•™
- å‚ä¸ç¼–æ’°ã€Šè¯­éŸ³ä¿¡æ¯å¤„ç†ç†è®ºä¸å®è·µã€‹æ•™æ